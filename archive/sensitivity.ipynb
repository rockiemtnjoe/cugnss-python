{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79c50964-c273-4028-8f92-9b85d783aee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, time\n",
    "from typing import Tuple\n",
    "import math\n",
    "from scipy.special import erfcinv\n",
    "from Include.preRun import pre_run\n",
    "from Include.makeCaTable import make_ca_table\n",
    "from init_settings import init_settings\n",
    "from Include.plotAcqSearch import plotAcqSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "749df8bb-070f-4d3c-8569-d4f2690ff5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#  Read datafile, return a complex numpy vector\n",
    "#  \n",
    "\n",
    "def readAcqData(settings, code_periods = None, skip = None, framing = False) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    read a datafile\n",
    "    settings is the standard settings object.  We will use:\n",
    "        fileName\n",
    "        skipNumberOfBytes\n",
    "        samplingFreq\n",
    "        codeFreqBasis\n",
    "        codeLength\n",
    "        acqNonCohTime\n",
    "        acqCoherentInt\n",
    "    code_periods is the number of 1mS code periods we need\n",
    "    skip is the number of samples in the datafile to skip\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        fid = open(settings.fileName, 'rb')\n",
    "    except Exception as e:\n",
    "        # Error while opening the data file.\n",
    "        raise RuntimeError(f\"Unable to read file {settings.fileName}: {e}\")\n",
    "    \n",
    "    # Initialize the multiplier to adjust for the data type\n",
    "    data_adapt_coeff = 1 if settings.fileType == 1 else 2\n",
    "    \n",
    "    # Move the starting point of processing. Can be used to start the\n",
    "    # signal processing at any point in the data record (e.g. good for long\n",
    "    # records or for signal processing in blocks).\n",
    "    if skip == None:\n",
    "        fid.seek(data_adapt_coeff * settings.skipNumberOfBytes, 0)\n",
    "    else:\n",
    "        fid.seek(data_adapt_coeff * skip, 0)\n",
    "    \n",
    "    # %% Acquisition ============================================================\n",
    "    samples_per_code = int(round(settings.codeLength * settings.samplingFreq / settings.codeFreqBasis))\n",
    "    # At least 42ms of signal are needed for fine frequency estimation\n",
    "\n",
    "    code_len = (2*settings.acqCoherentInt)*(settings.acqNonCohTime)\n",
    "    #code_len = max(42, settings.acqNonCohTime + 2)\n",
    "    \n",
    "    if code_periods == None:\n",
    "        num_samples = data_adapt_coeff * code_len * samples_per_code\n",
    "    else:\n",
    "        num_samples = code_periods * code_len * samples_per_code\n",
    "        \n",
    "    # Read data for acquisition.\n",
    "    if settings.dataType == 'schar':\n",
    "        dtype = np.int8\n",
    "    elif settings.dataType == 'short':\n",
    "        dtype = np.int16\n",
    "    elif settings.dataType == 'float':\n",
    "        dtype = np.float32\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported dataType: {settings.dataType}\")\n",
    "    data = np.fromfile(fid, dtype=dtype, count=num_samples)\n",
    "    if data.size < num_samples:\n",
    "        raise ValueError('Could not read enough data from the data file.')\n",
    "    \n",
    "    if data_adapt_coeff == 2:\n",
    "        # For complex data, separate I and Q\n",
    "        data_i = data[::2]\n",
    "        data_q = data[1::2]\n",
    "        data = data_i + 1j * data_q\n",
    "    fid.close()\n",
    "    # If the framing flag is set to be true, we fill 1mS of data down each column\n",
    "    # and there is one column for each code period\n",
    "    #\n",
    "    if framing == True:\n",
    "        data = data.reshape(-1, code_len)\n",
    "    return (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d661e866-7401-42b8-89f0-9cf25e522300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data File: /mnt/e/gnss_data/L1_IF20KHz_FS18MHz/L1_IF20KHz_FS18MHz.bin\n"
     ]
    }
   ],
   "source": [
    "settings = init_settings()\n",
    "print (f'Data File: {settings.fileName}')\n",
    "longdata = readAcqData(settings, framing = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f0d69d2-97b0-4675-bf9e-5069f511dbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7200000,)\n"
     ]
    }
   ],
   "source": [
    "print (longdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1004bdff-475c-49e9-ad24-04b8670cf0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000,)\n"
     ]
    }
   ],
   "source": [
    "PRN = 1\n",
    "thisCode = make_ca_table(PRN, settings)\n",
    "print (thisCode.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5f7d0098-55ca-4396-b84e-0c0a8866eee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectCASat (PRN, longData, settings, showStatus=False, nCoherent = None, nNonCoherent = None, pfa = None) -> dict:\n",
    "    \"\"\"\n",
    "    Attempt to detect the CA Code from the satellite with PRN\n",
    "    Receive a long data record from the file; this will be a single, long vector\n",
    "    Characteristics of the data and processing are provided in settings\n",
    "    \"\"\"\n",
    "    startTime = time.time()\n",
    "    if (showStatus==True):\n",
    "        print (\"Beginning Detection of PRN {PRN}\")\n",
    "\n",
    "    tSample = 1 / settings.samplingFreq\n",
    "    low_freq = -1 * settings.acqSearchBand\n",
    "    high_freq = settings.acqSearchBand\n",
    "\n",
    "    if nCoherent == None:\n",
    "        nCoherent = int(settings.acqCoherentInt)\n",
    "\n",
    "    if nNonCoherent == None:\n",
    "        nNonCoherent = int(settings.acqNonCohTime)\n",
    "    if showStatus == True:\n",
    "        print (f'Coherent Integrations: {nCoherent}, Non-Coherent Integrations: {nNonCoherent}')\n",
    "    if pfa == None:\n",
    "        pfa = 0.05  # This is the Probability of False Alarm for a satellite\n",
    "    \n",
    "    #\n",
    "    # Compute the number of samples in each code, and the number of codes\n",
    "    # that will be required\n",
    "    samples_per_code = int(round(settings.codeLength * settings.samplingFreq / settings.codeFreqBasis))\n",
    "    print (f'samples per code: {samples_per_code}')\n",
    "    numCodes = 2*nCoherent*nNonCoherent\n",
    "    totalSamples = samples_per_code*numCodes\n",
    "    #\n",
    "    # Make sure we've got enough data to do the required analysis\n",
    "    #\n",
    "    if len(longData) < totalSamples:\n",
    "        print ('Insufficient Data to perform acquisition')\n",
    "        print (f'{totalSamples} Samples Needed, received {len(longData)}')\n",
    "        return {\"success\": False, \"Error Message\": 'Insufficient Data'}\n",
    "        # In principal, we could read the required data from the file rather than exiting\n",
    "    \n",
    "    #\n",
    "    # Remove any residual DC carrier from the input signal\n",
    "    # This is vital because we will use a chi-squared distribution later\n",
    "    # Scale so ammplitude so either real or imaginary part has max\n",
    "    # amplitude of 1.000; longData becomes a vector with abs(signal) <= 1.0\n",
    "    #\n",
    "    rl = np.real(longData)\n",
    "    im = np.imag(longData)\n",
    "    rl = rl - np.mean(rl)\n",
    "    im = im - np.mean(im)\n",
    "    max_sample = np.max(np.concatenate((rl, im)))\n",
    "    longData = (0.5 / max_sample) * (rl + (1j * im))\n",
    "    #\n",
    "    # Mix longData down to baseband (nominally zero Hz IF)\n",
    "    if settings.IF != 0.0:\n",
    "        phase_points = np.arange(len(longData)) * 2 * np.pi * tSample * settings.IF\n",
    "        loCarrier = np.exp(-1j * phase_points)\n",
    "        longData = longData * loCarrier\n",
    "    #\n",
    "    # Make a test template for the PRN we're trying to detect\n",
    "    # Make templates in both the time and frequency domain\n",
    "    # Compute the frequency bins of the fft\n",
    "    \n",
    "    pnCodeSamples = make_ca_table(PRN, settings)\n",
    "    #print (type(pnCodeSamples), pnCodeSamples.shape)\n",
    "    #print (f'first several pnChips: {pnCodeSamples[:20]}')\n",
    "    zero_padding = np.zeros(samples_per_code*nCoherent)\n",
    "    #print (f'Zero Padding: {type(zero_padding)}, {zero_padding.shape}')\n",
    "    prnTemplateTD = np.concatenate((np.tile(pnCodeSamples,nCoherent), zero_padding))\n",
    "    #print (f'prnTemplateTD: {prnTemplateTD.shape}, {type(prnTemplateTD)}')\n",
    "    prnTemplateFD = np.conj(np.fft.fft(prnTemplateTD))\n",
    "    #\n",
    "    # Determine which frequency bins are in range for possible doppler\n",
    "    #\n",
    "    #print (f'prnTemplateFD shape: {prnTemplateFD.shape}')\n",
    "    freqs = np.fft.fftfreq(len(prnTemplateTD), tSample)\n",
    "    #print (f'frequency table: {freqs[:16]}')\n",
    "    freq_mask = (freqs >= low_freq) & (freqs <= high_freq)   # A boolean vector of frequency values in range\n",
    "    nFreqBins = np.sum(freq_mask)                            # Number of elements that are between lower and upper frequency\n",
    "    #\n",
    "    # Since we know the signal is at baseband of zero IF, \n",
    "    # we also know that half the frequencies are on either side of zero\n",
    "    initialShift = int((nFreqBins - 1) / 2)\n",
    "    #print (f'Initial Shift = {initialShift}, value = {freqs[initialShift]}')\n",
    "    freq_vals = freqs[freq_mask]                             # The values of the frequencies in bounds\n",
    "    #freq_idx = np.where(freq_mask)  #The indexes of the values that are in bounds\n",
    "    #print(f'frequencies: {freq_vals} \\n, indices: {freq_idx}')\n",
    "    #\n",
    "    # Reformat the data so there is one row vector for each \n",
    "    # Coherent Integration period.\n",
    "    # Each row will have (2*samples_per_code*nCoherent) samples\n",
    "    # It makes it a little cleaner to analyze\n",
    "    #\n",
    "    data = (longData[:totalSamples]).reshape((nNonCoherent,2*samples_per_code*nCoherent))\n",
    "    #print (data.shape)\n",
    "    #\n",
    "    # This is the main loop where we convolve the PRN sequence against the possible \n",
    "    # Frequency shifts\n",
    "    #\n",
    "    # Rows for doppler frequencies, time steps along columns\n",
    "    detector = np.zeros((nFreqBins, samples_per_code*nCoherent*2))\n",
    "    for nonCohIndex in range (nNonCoherent):\n",
    "        if showStatus == True:\n",
    "            print (\"Noncoherent Integration {nonCohIndex}\")\n",
    "        #\n",
    "        cohDetector = np.zeros((nFreqBins, 2*samples_per_code*nCoherent), dtype=complex)\n",
    "        #print (f'Looping through: {nonCohIndex}, {startCode}')\n",
    "        cohData = (data [nonCohIndex,:])\n",
    "        thisDataFD = np.fft.fft(cohData)   #Vector of signal data, nCoherent codes long\n",
    "        thisDataFD = np.roll(thisDataFD, initialShift)\n",
    "        # Loop through frequencies\n",
    "        this_freq = np.roll(freqs, initialShift)\n",
    "        for i in range(nFreqBins):\n",
    "            #print (f'doppler step {i}, frequency: {shifted_F[i]}')\n",
    "            doppler = this_freq[0]\n",
    "            #print (f'{i}, Freq: {doppler}')\n",
    "            #phase_points = np.arange(len(cohData))* 2 * np.pi * tSample * doppler\n",
    "            #mix_signal = np.exp(-1j * phase_points)\n",
    "            #testTD = mix_signal*cohData\n",
    "            #testFD = np.fft.fft(mix_signal*testTD)\n",
    "            #if (testFD == thisDataFD).all():\n",
    "                #print ('FFT data matches')\n",
    "            #else:\n",
    "                #print ('FFT data does not match')\n",
    "                #ratio = testFD / thisDataFD\n",
    "                #ratio_mag = np.abs(ratio)\n",
    "                #theta = np.angle(ratio) * 180 / np.pi\n",
    "                #print (f'ratio {ratio_mag[:3]}, angle = {theta[:3]}')\n",
    "            convolutionFD = thisDataFD * prnTemplateFD\n",
    "            convolutionTD = np.fft.ifft(convolutionFD)\n",
    "            cohDetector [i,:] = convolutionTD\n",
    "            thisDataFD = np.roll(thisDataFD, -1)\n",
    "            this_freq = np.roll(this_freq, -1)\n",
    "        detector += abs(cohDetector) ** 2  #square because for non-coherent integration we're averaging power\n",
    "    #\n",
    "    # Last step is to normalize the detector output based on sample rate and \n",
    "    # Number of non coherent detections\n",
    "    detector = (1/nNonCoherent) * (1 / samples_per_code) * detector\n",
    "\n",
    "    peak_val = np.max(detector)\n",
    "    variance = np.var(detector)\n",
    "    #\n",
    "    # This is an attempt to estimate the mean under no-signal conditions (H0 condition)\n",
    "    # Assume signal is present in only a few cells, and most cells are noise.\n",
    "    # Average across rows - most rows will be noise, and they'll be pretty consistent.  \n",
    "    # If we take the median of those cells, it should give us a good estimate of median under\n",
    "    # No-signal conditions.\n",
    "    row_mean = np.mean(detectArray, axis = 1)\n",
    "    meanval = np.median(row_mean)\n",
    "    sigma_sq = meanval / nCoherent\n",
    "    maxval = np.max(detectArray)\n",
    "    # Compute the detection threshold\n",
    "    #\n",
    "    # We want pfa to reflect the possibility of an error in the dataset we were given\n",
    "    # there are len(detectArray) samples that are mostly noise-like;\n",
    "    adjpfa = pfa / len(detectArray)\n",
    "    gamma = math.sqrt(2) * chi2.isf(adjpfa, 2*nCoherent)\n",
    "    threshold = sigma_sq * gamma\n",
    "    \n",
    "    signalDetected = (peak_val > threshold)\n",
    "    peakIndexFlat = np.argmax(detector)\n",
    "    peakIndex = np.unravel_index(peakIndexFlat, detector.shape)\n",
    "    \n",
    "    endTime = time.time()\n",
    "    runtime = endTime - startTime\n",
    "    return {\n",
    "        \"success\":True,\n",
    "        \"signalDetected\": signalDetected,\n",
    "        \"detector\":detector,\n",
    "        \"maxValue\": peak_val,\n",
    "        \"mean\": meanval,\n",
    "        \"pfa\": pfa,\n",
    "        \"threshold\": threshold,\n",
    "        \"index\": peakIndex,\n",
    "        \"peakfrequency\": freqs[peakIndex[0]],\n",
    "        \"peaksample\": peakIndex[1],\n",
    "        \"freqtable\": np.roll(freqs, initialShift)[:nFreqBins],\n",
    "        \"runtime\": runtime\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "70b3a7fc-a5a4-44d0-9339-4bf42a492c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples per code: 18000\n",
      "Completed in 6.762545347213745 seconds\n",
      "max_location: (np.int64(29), np.int64(87295)), peak: 13.542960430389813\n",
      "Signal Detected: True\n",
      "Maximum Correlation Value: 13.542960430389813\n",
      "Threshold Value: 2.225159971237518\n",
      "Peak / Threshold: 6.086286202091764\n",
      "Threshold / sdev: 19.72801924667061\n",
      "Mean Value: 2.43e-01, standard deviation: 1.13e-01\n",
      "peak / threshold ratio: 6.086286202091764\n",
      "(peak - mean) / standard dev: 117.9120478699724\n"
     ]
    }
   ],
   "source": [
    "#detectionResults = detectCASat(7, longdata, settings, nCoherent = 1, nNonCoherent = 1)\n",
    "detectionResults = detectCASat(7, longdata, settings, nCoherent = 5, nNonCoherent = 10)\n",
    "#print (detectionResults)\n",
    "runtime = detectionResults[\"runtime\"]\n",
    "print (f'Completed in {runtime} seconds')\n",
    "max_location = detectionResults[\"index\"]\n",
    "detectArray = detectionResults[\"detector\"]\n",
    "sig = detectionResults[\"signalDetected\"]\n",
    "mean = detectionResults[\"mean\"]\n",
    "sdev = math.sqrt(variance)\n",
    "threshold = detectionResults[\"threshold\"]\n",
    "maxVal = detectionResults[\"maxValue\"]\n",
    "print (f'max_location: {max_location}, peak: {detectArray[max_location]}')\n",
    "\n",
    "print (f'Signal Detected: {sig}')\n",
    "print (f'Maximum Correlation Value: {maxVal}')\n",
    "print (f'Threshold Value: {threshold}')\n",
    "print (f'Peak / Threshold: {maxVal / threshold}')\n",
    "print (f'Threshold / sdev: {threshold / sdev}')\n",
    "print (f'Mean Value: {mean:.2e}, standard deviation: {sdev:.2e}')\n",
    "print (f'peak / threshold ratio: {maxVal / threshold}')\n",
    "print (f'(peak - mean) / standard dev: {((maxVal - mean) / sdev)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0410ae-df8f-4e5d-b9f0-b183b1ea7b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "nCoherent = 5\n",
    "nNonCoherent = 5\n",
    "print (detectArray.size)\n",
    "#variance = np.var(detectArray)\n",
    "# This is an attempt to estimate the mean under no-signal conditions\n",
    "# Assume signal is present in only a few cells, and most cells are noise.\n",
    "# Average across rows - most rows will be noise, and they'll be pretty consistent.  \n",
    "# If we take the median of those cells, it should give us a good estimate of median under\n",
    "# No-signal conditions.\n",
    "row_mean = np.mean(detectArray, axis = 1)\n",
    "meanval = np.median(row_mean)\n",
    "sigma_sq = meanval / nCoherent\n",
    "medianval = np.median(detectArray)\n",
    "maxval = np.max(detectArray)\n",
    "pfa = 0.001 * (1/detectArray.size)\n",
    "gamma = math.sqrt(2) * chi2.isf(pfa, 2*nCoherent)\n",
    "print (f' max = {maxval}\\n mean= {meanval}\\n median= {medianval}\\n variance= {variance} \\n pfa = {pfa} \\n gamma = {gamma}')\n",
    "threshold = (sigma_sq / nNonCoherent) * gamma\n",
    "print (f'Threshold = {threshold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf860d27-ca96-4515-b11a-310d51f44981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/joe/cu_gnss/cugnss-python/plots/coarse_acquisition_PRN_99.jpg')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotAcqSearch(99, settings, detectArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6120ede5-3933-42c0-a6e8-a1137cc0961f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples per code: 18000\n",
      "Signal Detected = False\n",
      "Max Peak = 2.5297273212315887\n",
      "Threshold Value = 2.912605985473705\n",
      "DetectArray shape = (141, 180000)\n"
     ]
    }
   ],
   "source": [
    "nCoherent = 5\n",
    "nNonCoherent = 5\n",
    "pFA = 0.001\n",
    "\n",
    "sv23_Results = detectCASat(23, longdata, settings, nCoherent = nCoherent, nNonCoherent = nNonCoherent, pfa=pFA)\n",
    "\n",
    "detectArray = sv23_Results[\"detector\"]\n",
    "signalDetected = sv23_Results[\"signalDetected\"]\n",
    "maxValue = sv23_Results[\"maxValue\"]\n",
    "threshold = sv23_Results[\"threshold\"]\n",
    "print (f'Signal Detected = {signalDetected}')\n",
    "print (f'Max Peak = {maxValue}')\n",
    "print (f'Threshold Value = {threshold}')\n",
    "print (f'DetectArray shape = {detectArray.shape}')\n",
    "#variance = np.var(detectArray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc987669-7a07-434c-824c-ccef101ac930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " max = 1.9792349080467277\n",
      " mean= 0.24239955194985952\n",
      " sigma square = 0.0484799103899719\n",
      "  \n",
      " pfa = 0.0003546099290780142 \n",
      " gamma = 45.70218403482825\n",
      "Threshold = 2.215637786634478\n"
     ]
    }
   ],
   "source": [
    "# This is an attempt to estimate the mean under no-signal conditions (H0 condition)\n",
    "# Assume signal is present in only a few cells, and most cells are noise.\n",
    "# Average across rows - most rows will be noise, and they'll be pretty consistent.  \n",
    "# If we take the median of those cells, it should give us a good estimate of median under\n",
    "# No-signal conditions.\n",
    "row_mean = np.mean(detectArray, axis = 1)\n",
    "meanval = np.median(row_mean)\n",
    "sigma_sq = meanval / nCoherent\n",
    "medianval = np.median(detectArray)\n",
    "maxval = np.max(detectArray)\n",
    "#\n",
    "# We want pfa to reflect the possibility of an error in this measurement\n",
    "# there are len(detectArray) numbers we're going to evaluate\n",
    "pfa = 0.05 / len(detectArray)\n",
    "gamma = math.sqrt(2) * chi2.isf(pfa, 2*nCoherent)\n",
    "print (f' max = {maxval}\\n mean= {meanval}\\n sigma square = {sigma_sq}\\n  \\n pfa = {pfa} \\n gamma = {gamma}')\n",
    "threshold = sigma_sq * gamma\n",
    "print (f'Threshold = {threshold}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dfbb3ec4-6498-44ce-8d2d-eb3a8ff15be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/joe/cu_gnss/cugnss-python/plots/coarse_acquisition_PRN_101.jpg')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_list = sv23_Results[\"freqtable\"]\n",
    "plotAcqSearch(101, settings, detectArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07e7c385-321e-48bf-a312-703a5e5ba46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erf = 18.30703805327515\n",
      "gamma = 86.82827605679256, \n",
      "threshold = 1.9517493180741996\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2\n",
    "nCoherent = 5\n",
    "nNonCoherent = 10\n",
    "pfa = 0.05\n",
    "sample_variance = mean / nCoherent\n",
    "erf = chi2.isf(pfa, 2*nCoherent)\n",
    "print (f'erf = {erf}')\n",
    "\n",
    "threshold = (gamma / nNonCoherent )* math.sqrt(sample_variance)\n",
    "print (f'gamma = {gamma}, \\nthreshold = {threshold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84680899-da92-495c-965a-3fa168cc3ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal Detected: True\n",
      "Peak Value = 1.9792349080467277\n",
      "Signal Threshold: 0.8708356570726379\n",
      "Peak / Threshold: 2.27279957127621\n",
      "Threshold / sdev: 8.011308216402242\n",
      "Mean Value: 2.51e-01, standard deviation: 1.09e-01\n",
      "peak / threshold ratio: 2.27279957127621\n",
      "(peak - mean) / standard dev: 15.894414800459948\n"
     ]
    }
   ],
   "source": [
    "detected = sv23_Results [\"signalDetected\"]\n",
    "mean = sv23_Results[\"mean\"]\n",
    "variance = sv23_Results[\"var\"]\n",
    "sdev = math.sqrt(variance)\n",
    "threshold = sv23_Results[\"threshold\"]\n",
    "maxVal = sv23_Results[\"maxValue\"]\n",
    "\n",
    "print (f'Signal Detected: {sig}')\n",
    "print (f'Peak Value = {maxVal}')\n",
    "print (f'Signal Threshold: {threshold}')\n",
    "print (f'Peak / Threshold: {maxVal / threshold}')\n",
    "print (f'Threshold / sdev: {threshold / sdev}')\n",
    "print (f'Mean Value: {mean:.2e}, standard deviation: {sdev:.2e}')\n",
    "print (f'peak / threshold ratio: {maxVal / threshold}')\n",
    "print (f'(peak - mean) / standard dev: {((maxVal - mean) / sdev)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfa7c47a-476e-4432-9b10-ab61c961f922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/joe/cu_gnss/cugnss-python/plots/coarse_acquisition_PRN_101.jpg')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv23_matrix = sv23_Results[\"detector\"]\n",
    "plotAcqSearch(101, settings, sv23_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05936412-3c6a-4c78-8f1d-d7c18cb689c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5]\n",
      "[[0 1 2]\n",
      " [3 4 5]]\n",
      "[[2 0 1]\n",
      " [5 3 4]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(6)\n",
    "print(a)\n",
    "b = a.reshape((2,3))\n",
    "print (b)\n",
    "\n",
    "c = np.roll(b,shift=1, axis = 1)\n",
    "print (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0238d9c-2950-49e9-bfa7-f91e8fa87098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n",
      "[4 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2, 3, 4])\n",
    "print (a)\n",
    "b = np.roll(a, 1)\n",
    "print (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cf197c-b51b-48bc-a216-5ae5e825997a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
